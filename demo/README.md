# V-Stack Demonstration and Benchmark Tools

This directory contains demonstration tools and benchmarks for showcasing the three core novelties of V-Stack:

1. **Smart Client Scheduling** - Network-aware chunk selection
2. **Lightweight Consensus** - ChunkPaxos protocol
3. **Adaptive Redundancy** - Dynamic replication strategies

## Tool Categories

### üåê **Web Dashboard (Primary Interface)**
The main demo server provides a unified web interface to interact with the V-Stack system, run benchmarks, and visualize results.

### üìä **Real System Integration**
Tools that measure and interact with the actual running V-Stack system:
- `server.py` - Main demo server with web UI
- `benchmark.py` - Performance tests against live system
- `chaos_test.py` - Real-time system health monitoring

### üéÆ **Simulations**
Educational demonstrations that simulate V-Stack concepts (do NOT require running services):
- `smart_vs_naive_demo.py` - Simulated client comparison
- `adaptive_redundancy_demo.py` - Storage efficiency simulation
- `network_emulator.py` - Network condition simulator
- `run_demo.py` - Orchestrated simulation suite

## Quick Start Guide

### Option 1: Web Dashboard (Recommended)

The easiest way to explore V-Stack is through the web dashboard:

#### 1. Start the System
```bash
# Ensure all services are running (metadata-service, storage nodes, etc.)
docker-compose up -d
```

#### 2. Start the Demo Server
```bash
python demo/server.py
```

#### 3. Open Dashboard
Navigate to **http://localhost:8085** in your browser.

#### 4. Explore Features
- **Upload Videos**: Test the upload pipeline
- **System Performance**: View real-time metrics
- **Run Benchmarks**: Click "Run Benchmark Suite" to test against performance targets
- **Resilience Testing**: Click "Start Monitoring" to track system health
- **Storage Nodes**: Monitor node status in real-time

### Option 2: Command-Line Benchmarks

Run benchmarks directly from the command line:

```bash
# Test system performance
python demo/benchmark.py

# Monitor system resilience (60 seconds)
python demo/chaos_test.py
```

### Option 3: Simulated Demos

Run educational simulations (no services required):

```bash
# Compare smart vs naive client
python demo/smart_vs_naive_demo.py

# Demonstrate storage efficiency
python demo/adaptive_redundancy_demo.py

# Run full simulation suite
python demo/run_demo.py
```

## Tools Overview

### 1. Demo Web Server ‚≠ê **NEW**
**File:** `server.py`

**Type:** Real System Integration

Unified web dashboard that:
- Serves the interactive web UI
- Proxies requests to backend services
- Runs benchmarks against the live system
- Monitors system health in real-time
- Provides video upload interface

**Usage:**
```bash
python demo/server.py
# Open http://localhost:8085
```

**Environment Variables:**
```bash
DEMO_PORT=8085
METADATA_SERVICE_URL=http://localhost:8080
UPLOADER_SERVICE_URL=http://localhost:8084
CLIENT_DASHBOARD_URL=http://localhost:8086
STORAGE_NODE_1_URL=http://localhost:8081
STORAGE_NODE_2_URL=http://localhost:8082
STORAGE_NODE_3_URL=http://localhost:8083
```

### 2. Performance Benchmark Suite ‚≠ê **UPDATED**
**File:** `benchmark.py`

**Type:** Real System Integration

Tests the **actual running system** against performance requirements:
- System health checks
- API latency measurements
- Storage node response times
- Startup latency (manifest fetch)

**Usage:**
```bash
# Via Web UI (Recommended)
# Click "Run Benchmark Suite" button

# Via Command Line
python demo/benchmark.py

# Programmatically
from benchmark import PerformanceBenchmark
benchmark = PerformanceBenchmark(
    metadata_url='http://localhost:8080',
    storage_nodes=['http://localhost:8081', ...]
)
report = await benchmark.run_all_benchmarks()
```

### 3. Chaos Engineering Tests ‚≠ê **UPDATED**
**File:** `chaos_test.py`

**Type:** Real System Integration

Monitors the **live system** for failures and tracks resilience:
- Polls service health endpoints
- Detects node failures automatically
- Tracks recovery times
- Calculates system availability

**Usage:**
```bash
# Via Web UI (Recommended)
# Click "Start Monitoring (60s)" button

# Via Command Line
python demo/chaos_test.py
```

**Testing Tip:** While monitoring is running, manually interfere with the system:
```bash
# Stop a storage node
docker stop vstack-storage-node-1

# Wait for detection...

# Restart it
docker start vstack-storage-node-1
```

### 4. Performance Monitoring Dashboard

**File:** `../client/dashboard.html`, `../client/dashboard_server.py`

Real-time web dashboard showing:
- Buffer levels and health
- Node performance scores
- Throughput monitoring
- Chunk download sources
- Smart vs Naive comparison
- Performance metrics over time

**Usage:**
```bash
python client/run_with_dashboard.py <video_id>
# Open http://localhost:8888 in browser
```

### 5. Network Emulator
**File:** `network_emulator.py`

**Type:** üéÆ Simulation

Simulates various network conditions:
- Normal operation
- High latency
- Low bandwidth
- Packet loss
- Node failures
- Degraded conditions
- Recovery scenarios

**Usage:**
```python
from network_emulator import NetworkEmulator, DemoScenario

emulator = NetworkEmulator()
scenario = DemoScenario(emulator, node_urls)
await scenario.run_full_demo()
```

### 6. Smart vs Naive Comparison
**File:** `smart_vs_naive_demo.py`

**Type:** üéÆ Simulation

Side-by-side comparison demonstrating:
- Startup latency differences
- Rebuffering event reduction
- Throughput improvements
- Buffer health comparison
- Automatic node selection benefits

**Usage:**
```bash
python demo/smart_vs_naive_demo.py
```

**Expected Results:**
- 30-50% faster startup
- 70% fewer rebuffering events
- 30% higher throughput
- 20% better buffer health


### 4. Consensus Visualization
**Files:** `consensus_visualization.html`, `consensus_demo.py`

Interactive visualization of ChunkPaxos protocol:
- Normal operation flow
- Concurrent uploader conflict resolution
- Node failure handling
- Ballot number progression
- Message timeline

**Usage:**
```bash
python demo/consensus_demo.py
# Open http://localhost:8889 in browser
```

**Features:**
- Step-by-step protocol execution
- Three demonstration scenarios
- Real-time message timeline
- Educational explanations

### 5. Comprehensive Benchmark Suite
**File:** `benchmark.py`

Automated performance testing against all requirements:
- Startup latency (<2s)
- Rebuffering events (‚â§1)
- Average buffer size (>20s)
- Storage node latency (<10ms)
- Concurrent operations (10+ uploads, 100+ clients)
- Average throughput (>40 Mbps)
- Load distribution
- Automatic failover

**Usage:**
```bash
python demo/benchmark.py
```

**Output:**
- Pass/fail for each metric
- Detailed measurements
- Overall performance score
- JSON report file

### 6. Chaos Engineering Tests
**File:** `chaos_test.py`

Random failure injection for resilience testing:
- Node failures
- Network latency spikes
- Packet loss
- Slow disk I/O
- Memory pressure

**Usage:**
```bash
python demo/chaos_test.py
```

**Purpose:**
- Validate system resilience
- Test automatic failover
- Verify graceful degradation
- Ensure consistency under failures

### 7. Automated Demo Runner
**File:** `run_demo.py`

Runs all demonstration scenarios in sequence:
1. Smart vs Naive comparison
2. Network condition scenarios
3. Summary and key findings

**Usage:**
```bash
python demo/run_demo.py
```

## Quick Start

### Run All Demonstrations
```bash
# 1. Start the full system
docker-compose up -d

# 2. Run automated demo
python demo/run_demo.py

# 3. View performance dashboard
python client/run_with_dashboard.py test-video-001
# Open http://localhost:8888

# 4. View consensus visualization
python demo/consensus_demo.py
# Open http://localhost:8889

# 5. Run benchmarks
python demo/benchmark.py

# 6. Run chaos tests
python demo/chaos_test.py
```

### Individual Demonstrations

#### Smart Client Benefits
```bash
python demo/smart_vs_naive_demo.py
```

Shows concrete performance improvements from intelligent scheduling.

#### Network Adaptation
```bash
python demo/network_emulator.py
```

Demonstrates how the smart client adapts to changing network conditions.

#### Consensus Protocol
```bash
python demo/consensus_demo.py
# Open browser to http://localhost:8889
```

Interactive visualization of ChunkPaxos consensus protocol.

#### Performance Validation
```bash
python demo/benchmark.py
```

Validates system meets all performance targets from requirements.

## Demonstration Scenarios

### Scenario 1: Normal Operation
- All nodes healthy
- Optimal performance
- Demonstrates baseline capabilities

### Scenario 2: Network Degradation
- Gradually increasing latency
- Bandwidth reduction
- Packet loss introduction
- Shows adaptive behavior

### Scenario 3: Node Failure
- Single node failure
- Automatic failover
- Continued operation with 2/3 nodes
- Demonstrates fault tolerance

### Scenario 4: Recovery
- Degraded conditions improving
- Node recovery
- Return to optimal performance
- Shows resilience

### Scenario 5: Chaos Test
- Random failures
- Multiple simultaneous issues
- Stress testing
- Validates robustness

## Performance Targets

The benchmark suite validates these targets from requirements:

| Metric | Target | Requirement |
|--------|--------|-------------|
| Startup Latency | < 2 seconds | 6.3 |
| Rebuffering Events | 0-1 per session | 8.5 |
| Average Buffer | > 20 seconds | 9.5 |
| Storage Node Latency | < 10ms | 2.4 |
| Concurrent Uploads | ‚â• 10 | 9.2 |
| Concurrent Playback | ‚â• 100 clients | 9.1 |
| Average Throughput | > 40 Mbps | 9.3 |
| Node Response Time | < 50ms | 9.1 |

## Key Findings

### Smart Client Advantages
- **30-50% faster startup** compared to naive round-robin
- **70% reduction in rebuffering** through intelligent scheduling
- **30% higher throughput** by selecting optimal nodes
- **Automatic failover** within 5 seconds of node failure

### Consensus Benefits
- **33% fewer messages** than standard Paxos (6 vs 9)
- **Parallel execution** for different chunks
- **Conflict resolution** with ballot numbers
- **Fault tolerance** with minority node failures

### System Resilience
- Continues operating with 1/3 nodes failed
- Maintains playback during network degradation
- Automatic recovery when conditions improve
- Graceful degradation under load

## Visualization Features

### Dashboard
- Real-time buffer level monitoring
- Node performance scores
- Chunk download source visualization
- Throughput meter
- Historical charts
- Smart vs Naive comparison

### Consensus Visualization
- Step-by-step protocol execution
- Message timeline
- Node state visualization
- Ballot number tracking
- Interactive scenarios

## Output Files

### Benchmark Results
- `benchmark_results.json` - Detailed benchmark data
- Pass/fail status for each test
- Measured vs target values
- Overall performance score

### Logs
- Console output with detailed progress
- Timestamped events
- Performance measurements
- Error conditions

## Troubleshooting

### Dashboard not loading
- Ensure dashboard server is running
- Check port 8888 is not in use
- Verify client is running

### Benchmark failures
- Check system resources
- Ensure all services are running
- Review individual test results
- Check network connectivity

### Consensus visualization not working
- Ensure port 8889 is available
- Check browser console for errors
- Verify HTML file exists

## Development

### Adding New Benchmarks
1. Add test method to `PerformanceBenchmark` class
2. Define performance target
3. Implement measurement logic
4. Add result to results list

### Adding New Scenarios
1. Define scenario in `DemoScenario` class
2. Implement network condition changes
3. Add to automated demo runner
4. Document expected behavior

### Customizing Visualizations
1. Edit HTML/CSS in visualization files
2. Update JavaScript for new features
3. Add API endpoints as needed
4. Test in multiple browsers

## References

- Design Document: `../.kiro/specs/distributed-video-storage/design.md`
- Requirements: `../.kiro/specs/distributed-video-storage/requirements.md`
- Dashboard Documentation: `../client/DASHBOARD.md`
- Architecture: `../ARCHITECTURE.md`
