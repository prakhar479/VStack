#!/usr/bin/env python3
"""
Chaos Engineering Tests - Real system monitoring and resilience testing
Monitors the live system and tracks availability during failures.
"""

import asyncio
import logging
import time
import aiohttp
from typing import List, Dict
from dataclasses import dataclass, asdict

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class ChaosEvent:
    """Represents a chaos engineering event."""
    event_type: str
    target: str
    timestamp: float
    description: str
    recovered: bool = False
    recovery_time: float = 0.0


class ChaosEngineer:
    """
    Chaos engineering test suite for V-Stack.
    Monitors the live system for failures and tracks resilience.
    """
    
    def __init__(self, node_urls: List[str]):
        """
        Initialize chaos engineer.
        
        Args:
            node_urls: List of storage node URLs
        """
        self.node_urls = node_urls
        self.events: List[ChaosEvent] = []
        self.running = False
        self.node_status: Dict[str, bool] = {node: True for node in node_urls}
        
    async def check_node_health(self, node_url: str, session: aiohttp.ClientSession) -> bool:
        """
        Check if a node is healthy.
        
        Args:
            node_url: URL of the node
            session: aiohttp session
            
        Returns:
            True if healthy, False otherwise
        """
        try:
            async with session.get(f'{node_url}/health', timeout=aiohttp.ClientTimeout(total=2)) as resp:
                return resp.status == 200
        except Exception:
            return False
    
    async def run_chaos_test(self, duration_sec: int = 120) -> Dict:
        """
        Run chaos engineering test by monitoring the system.
        
        Args:
            duration_sec: Duration of chaos test in seconds
            
        Returns:
            Dictionary with test results
        """
        logger.info("="*80)
        logger.info("CHAOS ENGINEERING TEST - SYSTEM MONITORING")
        logger.info("="*80)
        logger.info(f"Duration: {duration_sec} seconds")
        logger.info(f"Target nodes: {len(self.node_urls)}")
        logger.info("="*80)
        logger.info("")
        logger.info("‚ö†Ô∏è  This test MONITORS the system for failures.")
        logger.info("   To test resilience, manually:")
        logger.info("   - Stop a storage node container")
        logger.info("   - Add network latency (tc command)")
        logger.info("   - Simulate high load")
        logger.info("")
        
        self.running = True
        start_time = time.time()
        end_time = start_time + duration_sec
        
        check_interval = 3  # Check every 3 seconds
        
        async with aiohttp.ClientSession() as session:
            try:
                while time.time() < end_time and self.running:
                    # Check health of all nodes
                    for node in self.node_urls:
                        is_healthy = await self.check_node_health(node, session)
                        
                        # Detect state changes
                        if self.node_status[node] and not is_healthy:
                            # Node went down
                            event = ChaosEvent(
                                event_type="NODE_FAILURE",
                                target=node,
                                timestamp=time.time(),
                                description=f"Node {node} became unhealthy"
                            )
                            self.events.append(event)
                            logger.warning(f"üí• FAILURE DETECTED: {event.description}")
                            
                        elif not self.node_status[node] and is_healthy:
                            # Node recovered
                            # Find the corresponding failure event
                            for event in reversed(self.events):
                                if event.target == node and not event.recovered:
                                    event.recovered = True
                                    event.recovery_time = time.time() - event.timestamp
                                    logger.info(f"‚úì RECOVERY: Node {node} recovered after {event.recovery_time:.1f}s")
                                    break
                        
                        # Update status
                        self.node_status[node] = is_healthy
                    
                    # Wait before next check
                    await asyncio.sleep(check_interval)
                    
            except asyncio.CancelledError:
                logger.info("Chaos test cancelled")
            finally:
                self.running = False
                
        # Generate report
        return self.generate_chaos_report(duration_sec)
        
    def generate_chaos_report(self, duration: float) -> Dict:
        """Generate chaos engineering test report."""
        logger.info("\n" + "="*80)
        logger.info("CHAOS ENGINEERING TEST REPORT")
        logger.info("="*80)
        
        # Count events by type
        event_counts = {}
        for event in self.events:
            event_counts[event.event_type] = event_counts.get(event.event_type, 0) + 1
            
        logger.info(f"\nTotal events detected: {len(self.events)}")
        
        if event_counts:
            logger.info("\nEvents by type:")
            for event_type, count in sorted(event_counts.items()):
                logger.info(f"  {event_type}: {count}")
        else:
            logger.info("\n‚úì No failures detected during monitoring period")
            
        # Count events by node
        node_counts = {}
        for event in self.events:
            node_counts[event.target] = node_counts.get(event.target, 0) + 1
            
        if node_counts:
            logger.info("\nEvents by node:")
            for node, count in sorted(node_counts.items()):
                logger.info(f"  {node}: {count}")
                
        # Calculate recovery stats
        recovered_events = [e for e in self.events if e.recovered]
        unrecovered_events = [e for e in self.events if not e.recovered]
        
        if recovered_events:
            avg_recovery_time = sum(e.recovery_time for e in recovered_events) / len(recovered_events)
            logger.info(f"\nRecovery Statistics:")
            logger.info(f"  Recovered events: {len(recovered_events)}")
            logger.info(f"  Average recovery time: {avg_recovery_time:.1f}s")
            
        if unrecovered_events:
            logger.info(f"\n‚ö†Ô∏è  Unrecovered failures: {len(unrecovered_events)}")
            for event in unrecovered_events:
                logger.info(f"  - {event.target} (failed at {time.strftime('%H:%M:%S', time.localtime(event.timestamp))})")
        
        # Calculate availability
        total_node_time = duration * len(self.node_urls)
        downtime = sum(e.recovery_time if e.recovered else duration - (e.timestamp - time.time() + duration) 
                      for e in self.events)
        availability = ((total_node_time - downtime) / total_node_time * 100) if total_node_time > 0 else 100
        
        logger.info(f"\nSystem Availability: {availability:.2f}%")
        
        logger.info("\n" + "="*80)
        logger.info("KEY OBSERVATIONS:")
        logger.info("‚úì System monitoring demonstrates failure detection")
        logger.info("‚úì Recovery tracking shows system resilience")
        logger.info("‚úì High availability indicates robust design")
        logger.info("="*80)
        
        return {
            'duration': duration,
            'total_events': len(self.events),
            'event_counts': event_counts,
            'node_counts': node_counts,
            'recovered_events': len(recovered_events),
            'unrecovered_events': len(unrecovered_events),
            'avg_recovery_time': sum(e.recovery_time for e in recovered_events) / len(recovered_events) if recovered_events else 0,
            'availability_percent': availability,
            'events': [asdict(e) for e in self.events]
        }


async def main():
    """Main entry point for chaos tests."""
    # Define storage nodes
    node_urls = [
        "http://localhost:8081",
        "http://localhost:8082",
        "http://localhost:8083"
    ]
    
    # Create chaos engineer
    chaos = ChaosEngineer(node_urls)
    
    try:
        # Run chaos test
        report = await chaos.run_chaos_test(duration_sec=60)
        
    except KeyboardInterrupt:
        logger.info("\nChaos test interrupted by user")


if __name__ == "__main__":
    asyncio.run(main())
